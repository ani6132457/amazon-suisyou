# app.py
import re
import pandas as pd
import requests
import streamlit as st
from bs4 import BeautifulSoup
from urllib.parse import urljoin

st.set_page_config(page_title="ç™ºæ³¨æ¨å¥¨ + æ¥½å¤©ç”»åƒï¼ˆsale_descæ–¹å¼ï¼‰", layout="wide")

# SKUã®7æ¡ â†’ æ¥½å¤©URLï¼ˆã‚ãªãŸæŒ‡å®šï¼‰
RAKUTEN_ITEM = "https://item.rakuten.co.jp/hype/{}/"

DEFAULT_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/121.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "ja-JP,ja;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
    "Connection": "keep-alive",
    "Referer": "https://item.rakuten.co.jp/",
}

# ----------------- utilities -----------------
def read_inventory_csv(uploaded_file) -> pd.DataFrame:
    try:
        return pd.read_csv(uploaded_file, encoding="cp932")
    except Exception:
        uploaded_file.seek(0)
        return pd.read_csv(uploaded_file, encoding="utf-8")

def normalize_text(x) -> str:
    if pd.isna(x):
        return ""
    return str(x).strip()

def extract_7digits_from_sku(sku: str) -> str | None:
    """
    SKUã® 'X' ã‚ˆã‚Šå‰ã®éƒ¨åˆ†ã‹ã‚‰7æ¡ã®æ•°å­—ã‚’å–ã‚Šå‡ºã™æƒ³å®šã€‚
    ä¾‹: 7987482X11Y11 -> 7987482
    """
    if not sku:
        return None
    sku = str(sku).strip()

    head = sku.split("X")[0]
    m = re.search(r"(\d{7})", head)
    if m:
        return m.group(1)

    m2 = re.search(r"(\d{7})", sku)
    return m2.group(1) if m2 else None

# ----------------- VBAäº’æ›ï¼šsale_descå†…ã®img src -----------------
def extract_img_from_sale_desc(html: str, base_url: str) -> str | None:
    """
    VBAã®ãƒ­ã‚¸ãƒƒã‚¯ã¨åŒã˜ï¼š
    <span class="sale_desc"> ã‚’æ¢ã—ã¦ã€ãã®ä¸­ã®æœ€åˆã® <img> ã® src ã‚’è¿”ã™ã€‚
    BeautifulSoupã§å®‰å…¨ã«ã‚„ã‚‹ç‰ˆã€‚
    """
    soup = BeautifulSoup(html, "lxml")

    span = soup.find("span", class_="sale_desc")
    if not span:
        return None

    img = span.find("img")
    if not img:
        return None

    src = img.get("src") or ""
    src = src.strip()
    if not src:
        return None

    # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã«å‚™ãˆã¦çµ¶å¯¾URLåŒ–
    return urljoin(base_url, src)

@st.cache_data(show_spinner=False, ttl=60 * 60 * 24)
def get_image_url_from_page(url: str) -> tuple[str | None, str]:
    """
    URLã‹ã‚‰HTMLã‚’å–å¾—ã—ã¦ sale_desc -> img src ã‚’æŠ½å‡ºã€‚
    æˆ»ã‚Šå€¤: (img_url or None, status_message)
    """
    if not url:
        return None, "URLãªã—"

    try:
        r = requests.get(url, headers=DEFAULT_HEADERS, timeout=20)
        if r.status_code != 200:
            return None, f"HTTP {r.status_code}"

        # æ–‡å­—åŒ–ã‘å¯¾ç­–ï¼ˆrequestsãŒèª¤åˆ¤å®šã™ã‚‹ã“ã¨ãŒã‚ã‚‹ï¼‰
        # ã¾ãš apparent_encoding ã‚’ä½¿ã„ã¤ã¤ã€å£Šã‚Œã‚‹å ´åˆã¯ãã®ã¾ã¾
        try:
            r.encoding = r.apparent_encoding
        except Exception:
            pass

        html = r.text

        img_url = extract_img_from_sale_desc(html, base_url=url)
        if img_url:
            return img_url, "OK"
        else:
            return None, "sale_descãªã—/ imgãªã—"
    except Exception as e:
        return None, f"ERROR: {type(e).__name__}"

def choose_page_url(row: pd.Series, url_colname: str | None) -> str | None:
    """
    ç”»åƒå–å¾—å…ƒURLã‚’æ±ºã‚ã‚‹ã€‚
    1) CSVã«URLåˆ—ãŒã‚ã‚‹ãªã‚‰ãã‚Œã‚’å„ªå…ˆï¼ˆVBAã¨åŒã˜é‹ç”¨ï¼‰
    2) ãªã‘ã‚Œã°SKUã‹ã‚‰7æ¡ã‚’ä½œã£ã¦æ¥½å¤©URLã‚’ç”Ÿæˆ
    """
    if url_colname and url_colname in row.index:
        u = normalize_text(row.get(url_colname, ""))
        if u.startswith("http"):
            return u

    sku = normalize_text(row.get("Merchant SKU", ""))
    code7 = extract_7digits_from_sku(sku)
    if code7:
        return RAKUTEN_ITEM.format(code7)

    return None

# ----------------- UI -----------------
st.title("ğŸ“¦ ç™ºæ³¨æ¨å¥¨é † + ç”»åƒURLå–å¾—ï¼ˆVBAäº’æ›: sale_descâ†’img srcï¼‰")
st.caption("ç”»åƒã¯URLå…ˆHTMLã® `<span class='sale_desc'>` å†…ã®æœ€åˆã® `<img src>` ã‚’å–å¾—ã—ã¾ã™ï¼ˆVBAã¨åŒã˜æ–¹å¼ï¼‰ã€‚")

uploaded = st.file_uploader("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
if not uploaded:
    st.stop()

df = read_inventory_csv(uploaded)

# å¿…é ˆåˆ—
required_cols = ["ASIN", "æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"CSVã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}")
    st.stop()

df["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"] = pd.to_numeric(df["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"], errors="coerce").fillna(0).astype(int)

# æ–‡å­—åˆ—åˆ—
df["ASIN"] = df["ASIN"].map(normalize_text)
if "Merchant SKU" in df.columns:
    df["Merchant SKU"] = df["Merchant SKU"].map(normalize_text)

# URLåˆ—ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é¸ã°ã›ã‚‹ï¼ˆã‚ã‚Œã°ï¼‰
url_candidates = [c for c in df.columns if "url" in c.lower() or "URL" in c or "Url" in c]
url_colname = None
if url_candidates:
    url_colname = st.selectbox("ï¼ˆä»»æ„ï¼‰ç”»åƒå–å¾—å…ƒURLã®åˆ—ã‚’é¸æŠï¼ˆVBAã®Cåˆ—ã«ç›¸å½“ï¼‰", ["(ä½¿ã‚ãªã„)"] + url_candidates, index=0)
    if url_colname == "(ä½¿ã‚ãªã„)":
        url_colname = None
else:
    st.info("CSVå†…ã«URLã£ã½ã„åˆ—ãŒè¦‹å½“ãŸã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚SKUâ†’7æ¡â†’æ¥½å¤©URLç”Ÿæˆã§å–å¾—ã—ã¾ã™ã€‚")

# ãƒ•ã‚£ãƒ«ã‚¿
left, mid, right = st.columns([1.6, 1.1, 1.3], gap="large")
with left:
    query = st.text_input("ğŸ” SKU ã¾ãŸã¯ ASIN ã§æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´OKï¼‰", placeholder="ä¾‹: 7987482 / B0DG... / 7987 ...")
    st.caption("ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®šã™ã‚‹ã¨ AND æ¤œç´¢ã«ãªã‚Šã¾ã™ã€‚")
with mid:
    only_positive = st.checkbox("ç™ºæ³¨æ¨å¥¨ãŒ0ã¯é™¤å¤–", value=True)
    min_qty = st.number_input("æœ€ä½ç™ºæ³¨æ¨å¥¨æ•°", min_value=0, value=1, step=1)
with right:
    max_cards = st.number_input("æœ€å¤§è¡¨ç¤ºä»¶æ•°", min_value=1, max_value=2000, value=200, step=50)
    img_width = st.slider("ç”»åƒã‚µã‚¤ã‚º", min_value=30, max_value=200, value=60, step=10)

view = df.copy()
if only_positive:
    view = view[view["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"] > 0]
view = view[view["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"] >= int(min_qty)]

q = (query or "").strip()
if q:
    tokens = [t for t in re.split(r"\s+", q) if t]
    if "Merchant SKU" in view.columns:
        hay = (view["Merchant SKU"].fillna("") + " " + view["ASIN"].fillna("")).str.lower()
    else:
        hay = view["ASIN"].fillna("").str.lower()

    mask = pd.Series(True, index=view.index)
    for t in tokens:
        t = t.lower()
        mask &= hay.str.contains(re.escape(t), na=False)
    view = view[mask]

# ä¸¦ã³æ›¿ãˆ
view = view.sort_values("æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡", ascending=False).reset_index(drop=True)

st.write(f"è¡¨ç¤ºä»¶æ•°: **{len(view)}**")
st.divider()

# ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆè»½é‡ï¼‰
with st.expander("ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆè»½é‡ï¼‰"):
    show_cols = [c for c in ["Merchant SKU", "å•†å“å", "ASIN", "æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"] if c in view.columns]
    st.dataframe(view[show_cols], use_container_width=True, height=320)

# ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
view_cards = view.head(int(max_cards))

for _, row in view_cards.iterrows():
    asin = normalize_text(row["ASIN"])
    qty = int(row["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"])
    sku = normalize_text(row.get("Merchant SKU", ""))
    name = normalize_text(row.get("å•†å“å", ""))

    page_url = choose_page_url(row, url_colname=url_colname)
    img_url, status = get_image_url_from_page(page_url) if page_url else (None, "URLç”Ÿæˆä¸å¯")

    st.markdown(
        """
        <div style="
            border: 1px solid rgba(0,0,0,0.08);
            border-radius: 14px;
            padding: 12px 12px 6px 12px;
            background: rgba(0,0,0,0.015);
        ">
        """,
        unsafe_allow_html=True,
    )

    col_img, col_info, col_qty = st.columns([0.6, 3.8, 1.2], gap="medium")

    with col_img:
        if img_url:
            st.image(img_url, width=int(img_width))
        else:
            st.caption(f"ç”»åƒãªã—\n({status})")

    with col_info:
        if sku:
            st.markdown(f"**SKU:** `{sku}`")
        st.markdown(f"**ASIN:** `{asin}`")
        if name:
            st.caption(name)
        if page_url:
            st.markdown(f"**å–å¾—å…ƒURL:** {page_url}")
        else:
            st.caption("å–å¾—å…ƒURLã‚’ä½œã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆSKUã‹ã‚‰7æ¡æŠ½å‡ºå¤±æ•— or URLåˆ—æœªæŒ‡å®šï¼‰")

    with col_qty:
        st.markdown(
            f"""
            <div style="
                border-radius: 14px;
                padding: 12px 10px;
                border: 1px solid rgba(255,0,0,0.25);
                background: rgba(255,0,0,0.07);
                text-align: center;
            ">
                <div style="font-size: 12px; opacity: 0.75;">ç™ºæ³¨æ¨å¥¨</div>
                <div style="font-size: 36px; font-weight: 900; color: #d40000; line-height: 1.05;">
                    {qty}
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

    st.markdown("</div>", unsafe_allow_html=True)
    st.divider()
