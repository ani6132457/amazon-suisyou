# app.py
import os
import re
import pandas as pd
import streamlit as st
from bs4 import BeautifulSoup
from urllib.parse import urljoin

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

st.set_page_config(page_title="æ¥½å¤©ç”»åƒ + ç™ºæ³¨æ¨å¥¨ï¼ˆé«˜é€ŸUIï¼‰", layout="wide")

RAKUTEN_ITEM = "https://item.rakuten.co.jp/hype/{}/"

# ---------- CSV ----------
def read_inventory_csv(uploaded_file) -> pd.DataFrame:
    try:
        return pd.read_csv(uploaded_file, encoding="cp932")
    except Exception:
        uploaded_file.seek(0)
        return pd.read_csv(uploaded_file, encoding="utf-8")

def normalize_text(x) -> str:
    if pd.isna(x):
        return ""
    return str(x).strip()

def extract_7digits_from_sku(sku: str) -> str | None:
    if not sku:
        return None
    sku = str(sku).strip()
    head = sku.split("X")[0]
    m = re.search(r"(\d{7})", head)
    if m:
        return m.group(1)
    m2 = re.search(r"(\d{7})", sku)
    return m2.group(1) if m2 else None

# ---------- HTML parse ----------
def extract_img_from_sale_desc(html: str, base_url: str) -> str | None:
    soup = BeautifulSoup(html, "lxml")
    span = soup.find("span", class_="sale_desc")
    if not span:
        return None
    img = span.find("img")
    if not img:
        return None
    src = (img.get("src") or "").strip()
    if not src:
        return None
    return urljoin(base_url, src)

# ---------- Selenium (Cloud-ready) ----------
def detect_chrome_binary() -> str:
    candidates = [
        os.environ.get("CHROME_BINARY", ""),
        "/usr/bin/chromium",
        "/usr/bin/chromium-browser",
        "/usr/bin/google-chrome",
        "/usr/bin/google-chrome-stable",
    ]
    for c in candidates:
        if c and os.path.exists(c):
            return c
    return ""

def detect_chromedriver_path() -> str:
    candidates = [
        os.environ.get("CHROMEDRIVER_PATH", ""),
        "/usr/bin/chromedriver",
        "/usr/lib/chromium/chromedriver",
    ]
    for c in candidates:
        if c and os.path.exists(c):
            return c
    return ""

@st.cache_resource
def get_driver():
    chrome_bin = detect_chrome_binary()
    chromedriver_path = detect_chromedriver_path()

    opts = Options()
    opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--window-size=1200,900")
    opts.add_argument("--lang=ja-JP")

    opts.add_argument(
        "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/121.0.0.0 Safari/537.36"
    )

    if chrome_bin:
        opts.binary_location = chrome_bin

    if chromedriver_path:
        service = Service(executable_path=chromedriver_path)
        driver = webdriver.Chrome(service=service, options=opts)
    else:
        driver = webdriver.Chrome(options=opts)

    driver.set_page_load_timeout(30)
    return driver

@st.cache_data(show_spinner=False, ttl=60 * 60 * 24)
def fetch_rakuten_image_by_url(url: str) -> dict:
    if not url:
        return {"img_url": None, "status": "URLãªã—"}

    driver = get_driver()
    try:
        driver.get(url)

        try:
            WebDriverWait(driver, 6).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "span.sale_desc"))
            )
        except Exception:
            pass

        html = driver.page_source
        final_url = driver.current_url

        if "Reference #" in html or "Access Denied" in html:
            return {"img_url": None, "status": "ãƒ–ãƒ­ãƒƒã‚¯"}

        img_url = extract_img_from_sale_desc(html, base_url=final_url)
        if img_url:
            return {"img_url": img_url, "status": "OK"}
        return {"img_url": None, "status": "imgãªã—"}

    except Exception as e:
        return {"img_url": None, "status": f"ERROR:{type(e).__name__}"}

# ---------- URLæ±ºå®š ----------
def choose_page_url_from_row(row: pd.Series, url_colname: str | None) -> str | None:
    if url_colname and url_colname in row.index:
        u = normalize_text(row.get(url_colname, ""))
        if u.startswith("http"):
            return u

    sku = normalize_text(row.get("Merchant SKU", ""))
    code7 = extract_7digits_from_sku(sku)
    if code7:
        return RAKUTEN_ITEM.format(code7)
    return None

# ----------------- UI -----------------
st.title("ğŸ“¦ ç™ºæ³¨æ¨å¥¨é †ï¼ˆå³è¡¨ç¤ºï¼‰ + ç”»åƒï¼ˆã‚ã¨ã‹ã‚‰å–å¾—ï¼‰")

uploaded = st.file_uploader("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
if not uploaded:
    st.stop()

df = read_inventory_csv(uploaded)

required_cols = ["ASIN", "æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"CSVã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}")
    st.stop()

df["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"] = pd.to_numeric(df["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"], errors="coerce").fillna(0).astype(int)
df["ASIN"] = df["ASIN"].map(normalize_text)
if "Merchant SKU" in df.columns:
    df["Merchant SKU"] = df["Merchant SKU"].map(normalize_text)

# URLåˆ—å€™è£œ
url_candidates = [c for c in df.columns if "url" in c.lower() or "URL" in c or "Url" in c]
url_colname = None
if url_candidates:
    url_colname = st.selectbox("ï¼ˆä»»æ„ï¼‰å–å¾—å…ƒURLåˆ—ï¼ˆVBAã®Cåˆ—ç›¸å½“ï¼‰", ["(ä½¿ã‚ãªã„)"] + url_candidates, index=0)
    if url_colname == "(ä½¿ã‚ãªã„)":
        url_colname = None

# ãƒ•ã‚£ãƒ«ã‚¿
left, mid, right = st.columns([1.6, 1.1, 1.3], gap="large")
with left:
    query = st.text_input("ğŸ” SKU ã¾ãŸã¯ ASIN ã§æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´OKï¼‰", placeholder="ä¾‹: 7987070 / B0DG... / 7987 ...")
    st.caption("ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®šã™ã‚‹ã¨ AND æ¤œç´¢ã«ãªã‚Šã¾ã™ã€‚")
with mid:
    only_positive = st.checkbox("ç™ºæ³¨æ¨å¥¨ãŒ0ã¯é™¤å¤–", value=True)
    min_qty = st.number_input("æœ€ä½ç™ºæ³¨æ¨å¥¨æ•°", min_value=0, value=1, step=1)
with right:
    show_rows = st.number_input("ä¸€è¦§è¡¨ç¤ºä»¶æ•°ï¼ˆå…ˆã«è¡¨ç¤ºï¼‰", min_value=20, max_value=5000, value=300, step=50)

# è¡¨ç¤ºå¯†åº¦ï¼ˆå°ã•ãï¼‰
dense = st.checkbox("ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆè¡¨ç¤ºï¼ˆä½™ç™½ã‚’æ¸›ã‚‰ã™ï¼‰", value=True)
if dense:
    st.markdown(
        """
        <style>
        div[data-testid="stVerticalBlock"] { gap: 0.35rem; }
        div[data-testid="stMarkdown"] p { margin-bottom: 0.2rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )

view = df.copy()
if only_positive:
    view = view[view["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"] > 0]
view = view[view["æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡"] >= int(min_qty)]

q = (query or "").strip()
if q:
    tokens = [t for t in re.split(r"\s+", q) if t]
    if "Merchant SKU" in view.columns:
        hay = (view["Merchant SKU"].fillna("") + " " + view["ASIN"].fillna("")).str.lower()
    else:
        hay = view["ASIN"].fillna("").str.lower()
    mask = pd.Series(True, index=view.index)
    for t in tokens:
        t = t.lower()
        mask &= hay.str.contains(re.escape(t), na=False)
    view = view[mask]

# ä¸¦ã¹æ›¿ãˆ
view = view.sort_values("æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡", ascending=False).reset_index(drop=True)

# æ¥½å¤©URLåˆ—ã‚’äº‹å‰ã«ä½œã‚‹ï¼ˆã“ã“ã¯è»½ã„ï¼‰
view["rakuten_url"] = view.apply(lambda r: choose_page_url_from_row(r, url_colname=url_colname) or "", axis=1)

st.write(f"è¡¨ç¤ºä»¶æ•°: **{len(view)}**ï¼ˆä¸Šä½ã‹ã‚‰ {int(show_rows)} ä»¶ã‚’è¡¨ç¤ºï¼‰")

# ---- å³è¡¨ç¤ºï¼šä¸€è¦§ï¼ˆç”»åƒãªã—ï¼‰----
base_cols = []
if "Merchant SKU" in view.columns:
    base_cols.append("Merchant SKU")
base_cols += ["ASIN", "æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡", "rakuten_url"]
if "å•†å“å" in view.columns:
    base_cols.insert(0, "å•†å“å")

st.dataframe(view.head(int(show_rows))[base_cols], use_container_width=True, height=420)

st.divider()

# ---- ç”»åƒå–å¾—ï¼ˆã‚ã¨ã‹ã‚‰ï¼‰----
st.subheader("ğŸ–¼ï¸ ç”»åƒè¡¨ç¤ºï¼ˆæ™‚é–“ãŒã‹ã‹ã£ã¦ã‚‚OKï¼‰")

img_left, img_right = st.columns([1.4, 2.6], gap="large")

with img_left:
    img_top_n = st.number_input("ç”»åƒã‚’å–å¾—ã™ã‚‹ä¸Šä½ä»¶æ•°ï¼ˆå¤šã„ã»ã©é…ã„ï¼‰", min_value=10, max_value=int(show_rows), value=min(50, int(show_rows)), step=10)
    img_width = st.slider("ç”»åƒã‚µã‚¤ã‚ºï¼ˆå°ã•ãã™ã‚‹ã¨1ç”»é¢ã«å¢—ãˆã‚‹ï¼‰", min_value=30, max_value=120, value=45, step=5)
    start = st.button("ç”»åƒå–å¾—ã‚’é–‹å§‹ï¼ˆä¸Šä½Nä»¶ï¼‰", type="primary")

with img_right:
    st.caption("ã¾ãšä¸Šã®è¡¨ã§å…¨ä½“ã‚’ç´ æ—©ãç¢ºèª â†’ å¿…è¦ãªä¸Šä½ã ã‘ç”»åƒã‚’å–å¾—ã™ã‚‹é‹ç”¨ãŒé€Ÿã„ã§ã™ã€‚")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆURLâ†’img_urlï¼‰
if "img_cache" not in st.session_state:
    st.session_state["img_cache"] = {}

if start:
    target = view.head(int(img_top_n)).copy()

    # ç”»åƒè¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãƒªã‚¹ãƒˆ
    for idx, row in target.iterrows():
        sku = normalize_text(row.get("Merchant SKU", ""))
        asin = normalize_text(row.get("ASIN", ""))
        qty = int(row.get("æ¨å¥¨ã•ã‚Œã‚‹åœ¨åº«è£œå……æ•°é‡", 0))
        name = normalize_text(row.get("å•†å“å", ""))

        page_url = normalize_text(row.get("rakuten_url", ""))

        # å–å¾—æ¸ˆã¿ãªã‚‰å†å–å¾—ã—ãªã„
        if page_url in st.session_state["img_cache"]:
            img_url = st.session_state["img_cache"][page_url]
            status = "cache"
        else:
            res = fetch_rakuten_image_by_url(page_url)
            img_url = res.get("img_url")
            status = res.get("status")
            st.session_state["img_cache"][page_url] = img_url  # Noneã§ã‚‚ä¿æŒï¼ˆç„¡é™ãƒªãƒˆãƒ©ã‚¤é˜²æ­¢ï¼‰

        # 1è¡Œè¡¨ç¤ºï¼ˆè¶…ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆï¼‰
        c1, c2, c3, c4 = st.columns([0.4, 2.6, 0.9, 1.1], gap="small")
        with c1:
            if img_url:
                st.image(img_url, width=int(img_width))
            else:
                st.caption("â€”")

        with c2:
            # æƒ…å ±ã¯è©°ã‚ã‚‹ï¼ˆãƒªãƒ³ã‚¯ã‚‚è²¼ã‚Œã‚‹ãŒé•·ã„ã®ã§æ§ãˆã‚ã«ï¼‰
            t = []
            if name:
                t.append(f"{name}")
            if sku:
                t.append(f"SKU:{sku}")
            t.append(f"ASIN:{asin}")
            st.markdown("<br>".join(t), unsafe_allow_html=True)

        with c3:
            st.markdown(
                f"""
                <div style="
                    border-radius: 10px;
                    padding: 6px 8px;
                    border: 1px solid rgba(255,0,0,0.22);
                    background: rgba(255,0,0,0.06);
                    text-align: center;
                ">
                    <div style="font-size: 11px; opacity: 0.75;">ç™ºæ³¨æ¨å¥¨</div>
                    <div style="font-size: 22px; font-weight: 900; color: #d40000; line-height: 1.05;">
                        {qty}
                    </div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        with c4:
            # å–å¾—å…ƒURLã¯çŸ­ãï¼ˆå¿…è¦ãªã‚‰ã‚¯ãƒªãƒƒã‚¯ã§ãã‚‹ï¼‰
            if page_url:
                st.link_button("æ¥½å¤©ãƒšãƒ¼ã‚¸", page_url, use_container_width=True)
            st.caption(status)

        st.divider()
